{"cells":[{"cell_type":"code","execution_count":0,"outputs":[],"metadata":{"collapsed":false,"_kg_hide-input":false},"source":"\n\n```{R setup, include =FALSE}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(fmsb)\nlibrary(psych)\nlibrary(rpart)\nlibrary(RColorBrewer)\nlibrary(rpart.plot)\nraw_data <- read.csv(\"../input/Speed Dating Data.csv\")\n```\n\n\n```{R}\nraw_data$gender <- as.factor(raw_data$gender)\nraw_data$career_c <- as.factor(raw_data$career_c)\nraw_data$samerace <- as.factor(raw_data$samerace)\nraw_data$race <- as.factor(raw_data$race)\nraw_data$dec <- as.factor(raw_data$dec)\nraw_data$date <- as.factor(raw_data$date)\n```\n\n\n```{R}\ndata_career <- raw_data %>% \n  filter(!is.na(career_c)) %>% \n  select(iid,gender, career_c)\ndata_career <- unique(data_career, by = iid)\n\ncareer_label <- c(\"Lawyer\", \"Academic/Research\", \"Psychologist\",  \n                  \"Doctor/Medicine\", \"Engineer\", \"Creative Arts/Entertainment\", \n                  \"Banking/Business\", \"Real Estate\", \"International Affairs\", \n                  \"Undecided\", \"Social Work\", \"Speech Pathology\", \"Politics\", \n                  \"Sports/Athletics\", \"Other\", \"Journalism\", \"Architecture\")\n\nggplot(data = data_career) +\n  geom_bar(aes(career_c, fill=gender)) + \n  scale_x_discrete(label = career_label) + coord_flip() + \n  labs(title = \"Distribution of Intended Career Fields\", x = \"Career Field\", y = \"Count\") + \n  scale_fill_discrete(\"Gender\", labels = c(\"Female\", \"Male\"))\n```\n\nThe above stacked bar plot shows the distribution of intended career fields of the subjects. Each career field is graphed with its corresponding participant count. The part of the bar that is colored blue corresponds to the male count, and the part of the bar that is colored red corresponds to the female count. Based on the plot, it is clear that most of the participants intended to go into the Banking/Business or Academic/Research fields.  \n\n```{R}\ndata_age <- raw_data %>% filter(!is.na(age)) %>% select(iid, gender, age)\ndata_age <- filter(data_age, age < max(age))\ndata_age <- unique(data_age, by = iid)\n\nggplot(data = data_age, aes(x = age,fill = gender)) + coord_flip() + \n  geom_histogram(data = subset(data_age, gender == \"0\"), binwidth = 2, color = \"white\") +  \n  geom_histogram(data = subset(data_age, gender == \"1\"), \n                 aes(y = ..count.. * (-1)), binwidth = 2, color = \"white\") + \n  scale_y_continuous(breaks = seq(-70, 70, 10), labels = abs(seq(-70, 70, 10)))+ \n  scale_x_continuous(breaks = seq(10, 45, 5), labels = seq(10, 45,5)) + \n  labs(title = \"Distribution of Age\", x = \"Age\", y = \"Count\") + \n  scale_fill_discrete(\"Gender\", labels = c(\"Female\", \"Male\"))\n```\n\nThe above two-sided bar plot shows the distribution of age of the subjects. The left side of the bar plot corresponds to the male participants, and the right side of the bar plot corresponds to the female participants. Initially, a female participant aged 55 years was found but was removed as she was deemed an outlier. The plot shows a rather symmetric distribution for both genders. Most of the male and female participants were in their early to late twenties, which is reasonable as the subjects were all students at Columbia University’s graduate and professional schools. \n\n```{r}\ndata_race <- raw_data %>% filter(!is.na(race)) %>% select(iid, gender, race)\ndata_race <- unique(data_race, by = iid)\n\nrace_label <- c(\"Black/African American\", \"European/Caucasian American\", \n                \"Latino/Hispanic American\", \"Asian/Asian American\", \n                \"Naitive American\", \"Other\")\n\nggplot(data = data_race) + \n  geom_bar(aes(x = gender,fill = race), position = \"fill\") + \n  labs(title = \"Distribution of Race\", x = \"Gender\", y = \"Relative Frequency\") +\n  scale_fill_discrete(\"Race\", labels = race_label) + scale_y_continuous(labels = percent) +\n  scale_x_discrete(labels=c(\"0\" = \"Male\", \"1\" = \"Female\"))\n```\n\n\n\n```{R} \nraw_data <- raw_data %>% \n  mutate(sum1_1 = attr1_1 + sinc1_1 + intel1_1 + amb1_1 + shar1_1) %>%\n  mutate(attr1_1 = (attr1_1/sum1_1)*100) %>% \n  mutate(sinc1_1 = (sinc1_1/sum1_1)*100) %>% \n  mutate(intel1_1 = (intel1_1/sum1_1)*100) %>% \n  mutate(amb1_1 = (amb1_1/sum1_1)*100) %>% \n  mutate(shar1_1 = (shar1_1/sum1_1)*100) %>% \n  mutate(sum2_1 = attr2_1 + sinc2_1 + intel2_1 + amb2_1 + shar2_1) %>%\n  mutate(attr2_1 = (attr2_1/sum2_1)*100) %>% \n  mutate(sinc2_1 = (sinc2_1/sum2_1)*100) %>% \n  mutate(intel2_1 = (intel2_1/sum2_1)*100) %>% \n  mutate(amb2_1 = (amb2_1/sum2_1)*100) %>% \n  mutate(shar2_1 = (shar2_1/sum2_1)*100) \n\ndata_features <- raw_data %>% filter(!is.na(sum1_1)) %>% \n  filter(!is.na(sum2_1)) %>% select(iid, gender, attr1_1:shar2_1)\ndata_features <- unique(data_features, by = idd) \n\nmen <- filter(data_features, gender ==\"1\")\nwomen <-filter(data_features, gender ==\"0\") \n\nrow_label <- c(\"Self\", \"Majority\")\ncolumn_label <- c(\"Attractive\", \"Sincere\", \"Intelligent\", \n                  \"Fun\", \"Ambitious\", \"Shared Interests\")\n```\n\n#### Men\n\n```{R}\nradar_men <- as.data.frame(matrix(0, nrow = 2, ncol = 6))\ncolnames(radar_men) <- column_label\nrownames(radar_men) <- row_label\n\nfor (i in (1:nrow(radar_men))) {\n  for(j in c(1:ncol(radar_men))) {\n    if(i == 1) {\n      radar_men[i, j] <- mean(men[ , 2 + j])\n    }\n     if(i == 2){\n      radar_men[i,j] <- mean(women[ , 14 + j])\n    }  \n  }\n}\n\nradar_men = rbind(rep(40, 5) , rep(0, 5) , radar_men)\nradarchart(radar_men, pcol= c( rgb(0.2, 0.5, 0.5, 0.9), rgb(0.7, 0.5, 0.1, 0.9)), \n           pfcol = c(rgb(0.2, 0.5, 0.5, 0.4), rgb(0.7, 0.5, 0.1, 0.4)),  \n           plwd = 3 , plty = 1, vlcex = 0.8, \n           title = \"Attributes males find most important in their female partner\")\nlegend(x = 1, y = 1.2, legend = c(\"Male perspective\", \"Female perspective\"), \n       bty = \"n\", pch = 20 , col = c(rgb(0.2, 0.5, 0.5, 0.4), rgb(0.7, 0.5, 0.1, 0.4)), \n       text.col = \"black\", cex = 0.8, pt.cex = 2)\n```\n\nThis radar plot shows the attributes males find most important in their female partner from two perspectives. The blue area is from the male perspective, so it shows what males find most important in their female partner. The yellow area is from the female perspective, so it shows what females think males find most important in their female partner. While the attributes of shared interests, ambition, and fun seem to have similar weights of importance from both the male perspective and the female perspective, the other three attributes do not. Men tend put more importance on the attributes of sincerity and intelligence and less importance on the attractiveness attribute than women thought. Women also thought men would put the most importance on attractiveness, and while men do in fact put the most importance in this attribute out of the six possibilities, it is not to the extent that women thought. \n\n#### Women\n\n```{R}\nradar_women <- as.data.frame(matrix(0, nrow = 2, ncol = 6))\ncolnames(radar_women) <- column_label\nrownames(radar_women) <- row_label\n\nfor (i in (1:nrow(radar_women))) {\n  for(j in c(1:ncol(radar_women))) {\n    if(i == 1) {\n      radar_women[i,j] <- mean(women[ , 2 + j])\n    }\n     if( i == 2) {\n      radar_women[i,j] <- mean(men[ , 14 + j])\n    }  \n  }\n}\n\nradar_women = rbind(rep(40, 5) , rep(0, 5) , radar_women)\nradarchart(radar_women, pcol = c( rgb(0.8, 0.2, 0.5, 0.9), rgb(0.7, 0.5, 0.1, 0.9)), \n           pfcol = c(rgb(0.8, 0.2, 0.5, 0.4), rgb(0.7, 0.5, 0.1, 0.4)),  \n           plwd = 3 , plty = 1, vlcex = 0.8,\n           title = \"Attributes females find most important in their male partner\")\nlegend(x = 1, y = 1.2, legend = c(\"Female perspective\", \"Male perspective\"), \n       bty = \"n\", pch = 20 , col = c(rgb(0.8, 0.2, 0.5, 0.4) , rgb(0.7, 0.5, 0.1, 0.4)), \n       text.col = \"black\", cex = 0.8, pt.cex = 2)\n```\n\nThis radar plot shows the attributes females find most important in their male partner from two perspectives. The pink area is from the female perspective, so it shows what females find most important in their male partner. The yellow area is from the male perspective, so it shows what males think female find most important in their male partner. Similar to the first radar plot, the attributes of shared interests, ambition, and fun seem to have similar weights of importance from both the female perspective and the male perspective, and the other three, again, do not. Women seem to put more importance on the attributes of sincerity and intelligence and less importance on the attractiveness attribute than men thought. Men also thought women would put the most importance on the attractiveness attribute, just as women did to men. \n\nIt is interesting that both men and women overestimated the weight of importance of attractiveness and underestimated the weight of importance of sincerity and intelligence for the other gender. Perhaps this shows the skewed perspective of love and romantic attraction in today’s society. \n\nThe results of the radar plots seem to support the original hypotheses. However, it is important to note that while the partipants tended to respond in this way, their actual actions may not have been reflective of what they had initially said. Thus, further analysis had to be performed on the actual data from the speed dating events themselves. \n\n## Modeling I: Linear Regression\n\nTo begin the regression analysis, the data was manipulated so that the averages each subject’s ratings for the six attributes of attractiveness, sincerity, intelligence, fun, ambition, and shared interests were calculated. In each of the linear regression analyses, the independent variable was one of these average ratings. In the multiple regression analyses, the average ratings for all six attributes were considered. \n\nThe dependent variable for each of the analyses was the percent of times that a subject’s partner said they wanted to meet the subject for a second date. Because each speed dating event had a different numbers of participants, using the number of times a subject’s partner voted that they wanted to see the subject again seemed unfair. A percentage was taken so that the values could be compared relative to one another. \n\n```{R}\nregression <- raw_data %>% group_by(iid) %>% \n  summarize(gender = mean(as.numeric(gender)), \n            attr = mean(attr_o, na.rm = TRUE), \n            sinc = mean(sinc_o, na.rm = TRUE), \n            intel = mean(intel_o, na.rm = TRUE), \n            fun = mean(fun_o, na.rm = TRUE), \n            amb = mean(amb_o, na.rm = TRUE), \n            shar = mean(shar_o, na.rm = TRUE), \n            selected = sum(dec_o, na.rm = TRUE), n = n())  %>% \n  mutate(selected_perc = selected/n*100) %>% \n  filter(selected_perc > 0)\n```\n\n#### Men\n\nA pairs matrix was generated to visualize an overview of the relationships between each male subject’s average ratings for the six attributes and the percent of selections of the subject. Based on the matrix, the attributes with the greatest correlation with the percent of selections were attractiveness and fun. Linear regressions were performed with these attributes. Because the original hypothesis stated that women tend to find intelligence to be the most important attribute in their male partners, a linear regression for the intelligence attribute was also performed. As the pairs matrix initially showed, attractiveness has the strongest positive correlation with percent of selections with a correlation coefficient of 0.79. Intelligence has the lowest correlation with percent of selections among the three attributes selected with a correlation coefficient of 0.31.  \n\n```{R}\nregression_men <- regression %>% filter(gender == 1)\n\npairs.panels(regression_men[ , c(3:8, 11)], \n             method = \"pearson\", scale = TRUE, ellipses = FALSE, \n             labels = c(\"Attractive\", \"Sincere\", \"Intelligent\", \"Fun\", \n                        \"Ambitious\", \"Interests\", \"Selected\"), \n             cex.labels = 1.3, hist.col = \"lightblue\")\n\nreg_intel_men <- lm(selected_perc ~ intel, data = regression_men)\nsummary(reg_intel_men)\nplot(data = regression_men, selected_perc ~ intel, main = \"'Intelligence' Score vs Percent of selection\", xlab = \"'Intelligence' Score\", ylab = \"Percent of selection\") \nabline(reg_intel_men, col = \"blue\")\n\nreg_attr_men <- lm(selected_perc ~ attr, data = regression_men)\nsummary(reg_attr_men)\nplot(data = regression_men, selected_perc ~ attr, main = \"'Attractiveness' Score vs Percent of selection\", xlab = \"'Attractiveness' Score\", ylab = \"Percent of selection\") \nabline(reg_attr_men, col = \"blue\")\n\nreg_fun_men <- lm(selected_perc ~ fun, data = regression_men)\nsummary(reg_fun_men)\nplot(data=  regression_men, selected_perc ~ fun, main = \"'Fun' Score vs Percent of selection\", xlab = \"'Fun' Score\", ylab = \"Percent of selection\") \nabline(reg_fun_men, col = \"blue\")\n\nreg_mult_men<-lm(selected_perc ~ attr + sinc + intel + fun + amb + shar, \n                 data = regression_men)\nsummary(reg_mult_men)\n```\n\nThe multiple regression analysis shows that using a combination of all the attributes produced a moderately strong positive relationship with percent of selections. The adjusted R-squared value was 0.6474, meaning that 64.74% of the variation in the relationship between all the attributes and the percent of selections can be accounted for by the best-fit line from this regression analysis. The most statistically significant variables were attractiveness with the lowest p-value and fun with p-value equal to 0.000358. Sincerity also showed some degree of significance, but the attributes of sincerity, intelligence, and ambition had little importance in the model with p-values higher than 0.05. \n\n#### Women\n\nThe same procedure was repeated for females. A pairs matrix was generated to visualize an overview of the relationships between each female subject’s average ratings for the six attributes and the percent of selections of the subject. Based on the matrix, the attributes with the greatest correlation with the percent of selections were, again, attractiveness and fun, just as it was for the males, and also shared interests. Linear regressions were performed with these attributes. Attractiveness has the strongest positive correlation with percent of selections with a correlation coefficient of 0.74. This supports the original hypothesis that men find attractiveness to be the most important attribute in their female partners. Fun and shared interests both have moderately strong positive linear relationships with percent of selections as the correlation coefficients are 0.65 and 0.64 respectively. \n\n```{R}\nregression_women <- regression %>% filter(gender != 1)\n\npairs.panels(regression_women[ , c(3:8, 11)], \n             method = \"pearson\", scale = TRUE, ellipses = FALSE, \n             labels = c(\"Attractive\", \"Sincere\", \"Intelligent\", \"Fun\", \n                        \"Ambitious\", \"Interests\", \"Selected\"), \n             cex.labels = 1.3, hist.col = \"pink\")\n\nreg_attr_women <- lm(selected_perc ~ attr, data = regression_women)\nsummary(reg_attr_women)\nplot(data = regression_women, selected_perc ~ attr, main = \"'Attractiveness' Score vs Percent of selection\", xlab = \"'Attractiveness' Score\", ylab = \"Percent of selection\") \nabline(reg_attr_women, col = \"red\")\n\nreg_fun_women <- lm(selected_perc ~ fun, data = regression_women)\nsummary(reg_fun_women)\nplot(data = regression_women, selected_perc ~ fun, main = \"'Fun' Score vs Percent of selection\", xlab = \"'Fun' Score\", ylab = \"Percent of selection\") \nabline(reg_fun_women, col = \"red\")\n\nreg_shar_women <- lm(selected_perc ~ shar, data = regression_women)\nsummary(reg_shar_women)\nplot(data = regression_women, selected_perc ~ shar, main = \"'Shared Interests' Score vs Percent of selection\", xlab = \"'Shared Interests' Score\", ylab = \"Percent of selection\") \nabline(reg_shar_women, col = \"red\")\n\nreg_mult_women <- lm(selected_perc ~ attr + sinc + intel + fun + amb + shar, \n                     data = regression_women)\nsummary(reg_mult_women)\n```\n\nThe multiple regression analysis shows that using a combination of all the attributes produced a moderately strong positive relationship with percent of selections. The adjusted R-squared value was 0.5914, meaning that 59.14% of the variation in the relationship between all the attributes and the percent of selections can be accounted for by the best-fit line from this regression analysis. The most statistically significant variable was attractiveness with the lowest p-value. Shared interests and fun also showed moderate levels of significance, while other variables of sincerity, intelligence, and ambition had p-values higher than 0.05. \n\n## Modeling II: Decision Tree\n\nA second analysis was conducted using decision trees to find which attributes were most important to men and women in selecting their partners. In the first set of decision trees, the six attributes of attractiveness, sincerity, intelligence, fun, ambition, and shared interests were used. In the second, different attributes that were not previously analyzed were used, such as career field, race, and age. \n\n### Using the Original Six Attributes\n\n#### Men\n\nFor men, after training the classifier, the decision tree deemed that attractiveness and shared interests were the attributes that should be split on. For example, if a male participant’s average attractiveness rating was above 6.8 and their average shared interest rating was above 6.5, he had a 73% chance of being selected by his partner to have a second date. The accuracy of the decision tree was calculated to be above 70%, which is a moderately high accuracy.\n```{R}\nmen_tree <- raw_data %>% filter(gender == 1)\n\nmen_fit <- rpart(dec_o ~ attr_o + sinc_o + intel_o + fun_o + amb_o + shar_o, \n                 data = men_tree, method = \"class\")\nrpart.plot(men_fit)\n\nshuffled_men <- sample_n(men_tree, nrow(men_tree))\nsplit_men <- 0.8*nrow(shuffled_men)\ntrain_men <- shuffled_men[1:split_men, ]\ntest_men <- shuffled_men[(split_men + 1) : nrow(shuffled_men), ]\n\nmen_fit_test <- rpart(dec_o ~ attr_o + sinc_o + intel_o + fun_o + amb_o + shar_o, \n                      data = train_men, method = \"class\")\ntree_predictions_men <- predict(men_fit_test, test_men, type = \"class\")\nmean(tree_predictions_men == test_men$dec_o)\n```\n\n#### Women\n\nFor women, after training the classifier, the decision tree deemed that attractiveness, fun, and shared interests were the three attributes that should have been split on. For example, if a female participant’s average attractiveness rating was above 6.2 and their average fun rating was above 6.8, she had a 79% chance of being selected by her partner to have a second date. If a female participant’s average attractiveness rating was above 6.2 but their average fun rating was less that 6.8, she had a 62% change of being selected by her partner to have a second date if her average shared interest rating was above 4.5. The accuracy of the decision tree was calculated to be approximately 70%, which is a moderately high accuracy.\n\n```{R}\nwomen_tree <- raw_data %>% filter(gender != 1)\n\nwomen_fit <- rpart(dec_o ~ attr_o + sinc_o + intel_o + fun_o + amb_o + shar_o, \n                   data = women_tree, method = \"class\")\nrpart.plot(women_fit)\n\nshuffled_women <- sample_n(women_tree, nrow(women_tree))\nsplit_women <- 0.8*nrow(shuffled_women)\ntrain_women <- shuffled_women[1:split_women, ]\ntest_women <- shuffled_women[(split_women + 1) : nrow(shuffled_women), ]\n\nwomen_fit_test <-rpart(dec_o ~ attr_o + sinc_o + intel_o + fun_o + amb_o + shar_o, \n                       data = train_women, method = \"class\")\ntree_predictions_women <- predict(women_fit_test, test_women, type = \"class\")\nmean(tree_predictions_women == test_women$dec_o)\n```\n\n### Using New Attributes\n\nThe second set of decision trees used attributes not previously analyzed. These attributes include the number of date that the participant was for their partner, age, race, field of study, primary goal in participating in the speed dating event, how frequently the participant went on dates, and intended career field. \n\n#### Men\n\nFor men, the decision tree deemed that the best attributes to split on were frequency of dates a male participant went on in general, race, intended career field, and age. Based on the decision tree, men who went on dates less than twice a month, were of the Black/African American or Asian/Pacific Islander/Asian-American race, were intending to be in the career field of Academia/Research, and were more than 30 years old were more unfavorable by the female participants. \n\n```{R}\nmen_fit_2 <-rpart(dec_o ~ order + age + race + field_cd + goal + date + career_c, \n                  data = men_tree, method = \"class\")\nrpart.plot(men_fit_2)\n\nshuffled_men_2 <- sample_n(men_tree, nrow(men_tree))\nsplit_men_2 <- 0.8*nrow(shuffled_men_2)\ntrain_men_2 <- shuffled_men_2[1:split_men_2, ]\ntest_men_2 <- shuffled_men_2[(split_men_2 + 1) : nrow(shuffled_men_2), ]\n\nmen_fit_test_2 <-rpart(dec_o ~ order + age + race + field_cd + goal + date + career_c, \n                       data = train_men_2, method = \"class\")\ntree_predictions_men_2 <- predict(men_fit_test_2, test_men_2, type = \"class\")\nmean(tree_predictions_men_2 == test_men_2$dec_o)\n```\n\n\n#### Women\n\nFor women, the decision tree deemed that the best attributes to split on were career field, age, race, and field of study. Based on the decision tree, women who were intending to be in the career fields of Psychology, Engineering, Creative Arts/Entertainment, Social Work, Speech Pathology, Politics, Journalism, or Undecided were more unfavorable by the male participants. In addition, if the female participant was more than 32 years old, was of the Asian/Pacific Islander/Asian-American race, and studied Education, Biological Sciences/Chemistry/Physics, Social Work, Political Science/International Affairs, Film, Fine Arts/Arts Administration, Languages, Architecture, or were Undecided were also unfavorable candidates for a second date. \n\n\nwomen_fit_2 <- rpart(dec_o ~ order + age + race + field_cd + goal + date + career_c,\n                     data = women_tree, method = \"class\")\nrpart.plot(women_fit_2)\n\nshuffled_women_2 <- sample_n(women_tree, nrow(women_tree))\nsplit_women_2 <- 0.8*nrow(shuffled_women_2)\ntrain_women_2 <- shuffled_women_2[1:split_women_2, ]\ntest_women_2 <- shuffled_women_2[(split_women_2 + 1) : nrow(shuffled_women_2), ]\n\nwomen_fit_test_2 <- rpart(dec_o ~ order + age + race + field_cd + goal + date + career_c,\n                          data = train_women_2, method = \"class\")\ntree_predictions_women_2 <- predict(women_fit_test_2, test_women_2, type = \"class\")\nmean(tree_predictions_women_2 == test_women_2$dec_o)\n```\n\n"}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}